{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa9ed8ff-e559-40d0-81d9-330d8a698e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31961f6b-6f2c-49aa-b25c-b9787e7a84b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "      <th>author</th>\n",
       "      <th>channelId</th>\n",
       "      <th>videoId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UgyGTD1f_6mJCVyN3UZ4AaABAg</td>\n",
       "      <td>For a second i actually thoughr you borh had c...</td>\n",
       "      <td>7 months ago</td>\n",
       "      <td>@Leanne-c4r</td>\n",
       "      <td>UC_NLLZ_YYZOJ0sGe6XfacAg</td>\n",
       "      <td>zJ48vnQFz3I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ugwag8DP6KVkqnKLmuZ4AaABAg</td>\n",
       "      <td>I was thinking that was Adam and Eve have no c...</td>\n",
       "      <td>4 months ago</td>\n",
       "      <td>@carolnthenya6275</td>\n",
       "      <td>UCJ5xuIjvtVVKJ-8pcwf0hsw</td>\n",
       "      <td>zJ48vnQFz3I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UgwxbvHULhj1mhpplR14AaABAg</td>\n",
       "      <td>üòÖüòÇü§£his facial expression and gestic is pricele...</td>\n",
       "      <td>7 months ago</td>\n",
       "      <td>@angelikasteeb5757</td>\n",
       "      <td>UC7JDE-u8nApD-Q9bAMTvlEA</td>\n",
       "      <td>zJ48vnQFz3I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ugwym2ycekFrEXo40xt4AaABAg</td>\n",
       "      <td>you  got ray on  his facial expression isabell...</td>\n",
       "      <td>7 months ago</td>\n",
       "      <td>@mayrasalvador9991</td>\n",
       "      <td>UCjf9SZjCAWKWEX6gbO3EbAg</td>\n",
       "      <td>zJ48vnQFz3I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UgzYU8MiyLBm-34gwvV4AaABAg</td>\n",
       "      <td>You guys are so funny and the bedt‚ù§‚ù§‚ù§‚ù§‚ù§</td>\n",
       "      <td>7 months ago</td>\n",
       "      <td>@julietamadeleine7326</td>\n",
       "      <td>UCVVSl3cw8ZMnKLS4qJGPYOQ</td>\n",
       "      <td>zJ48vnQFz3I</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          cid  \\\n",
       "0  UgyGTD1f_6mJCVyN3UZ4AaABAg   \n",
       "1  Ugwag8DP6KVkqnKLmuZ4AaABAg   \n",
       "2  UgwxbvHULhj1mhpplR14AaABAg   \n",
       "3  Ugwym2ycekFrEXo40xt4AaABAg   \n",
       "4  UgzYU8MiyLBm-34gwvV4AaABAg   \n",
       "\n",
       "                                                text          time  \\\n",
       "0  For a second i actually thoughr you borh had c...  7 months ago   \n",
       "1  I was thinking that was Adam and Eve have no c...  4 months ago   \n",
       "2  üòÖüòÇü§£his facial expression and gestic is pricele...  7 months ago   \n",
       "3  you  got ray on  his facial expression isabell...  7 months ago   \n",
       "4            You guys are so funny and the bedt‚ù§‚ù§‚ù§‚ù§‚ù§  7 months ago   \n",
       "\n",
       "                  author                 channelId      videoId  \n",
       "0            @Leanne-c4r  UC_NLLZ_YYZOJ0sGe6XfacAg  zJ48vnQFz3I  \n",
       "1      @carolnthenya6275  UCJ5xuIjvtVVKJ-8pcwf0hsw  zJ48vnQFz3I  \n",
       "2     @angelikasteeb5757  UC7JDE-u8nApD-Q9bAMTvlEA  zJ48vnQFz3I  \n",
       "3     @mayrasalvador9991  UCjf9SZjCAWKWEX6gbO3EbAg  zJ48vnQFz3I  \n",
       "4  @julietamadeleine7326  UCVVSl3cw8ZMnKLS4qJGPYOQ  zJ48vnQFz3I  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('~/UTK /Spring 25/DATA 304/Final Project/data/comments/zJ48vnQFz3I.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5270310b-30b4-4d35-89f2-ce42f95359ec",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emoji\n",
      "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: emoji\n",
      "Successfully installed emoji-2.14.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0e4b7f9-f98e-4b18-8e97-43a7d9228679",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/anaconda3/lib/python3.11/site-packages (3.8.1)\n",
      "Collecting textblob\n",
      "  Downloading textblob-0.19.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.50.0-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.4.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.11/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.11/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.11/site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.11/site-packages (from nltk) (4.65.0)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.26.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.29.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (1.11.4)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Downloading textblob-0.19.0-py3-none-any.whl (624 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m624.3/624.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.50.0-py3-none-any.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading sentence_transformers-3.4.1-py3-none-any.whl (275 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m275.9/275.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.29.3-py3-none-any.whl (468 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m418.4/418.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, nltk, textblob, huggingface-hub, tokenizers, transformers, sentence-transformers\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.8.1\n",
      "    Uninstalling nltk-3.8.1:\n",
      "      Successfully uninstalled nltk-3.8.1\n",
      "Successfully installed huggingface-hub-0.29.3 nltk-3.9.1 safetensors-0.5.3 sentence-transformers-3.4.1 textblob-0.19.0 tokenizers-0.21.1 transformers-4.50.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk textblob transformers sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13b81248-85fd-4d4a-8d31-60c6f79668dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "\n",
    "def remove_emojis(text):\n",
    "    return emoji.replace_emoji(text, replace='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "919ec1ce-7b83-4f74-9caa-440c7e9caaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean_text'] = data['text'].apply(remove_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04f97f6e-42d0-4bca-9503-1bc6a37710fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>For a second i actually thoughr you borh had c...</td>\n",
       "      <td>For a second i actually thoughr you borh had c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I was thinking that was Adam and Eve have no c...</td>\n",
       "      <td>I was thinking that was Adam and Eve have no c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>üòÖüòÇü§£his facial expression and gestic is pricele...</td>\n",
       "      <td>his facial expression and gestic is pricelessm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you  got ray on  his facial expression isabell...</td>\n",
       "      <td>you  got ray on  his facial expression isabell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You guys are so funny and the bedt‚ù§‚ù§‚ù§‚ù§‚ù§</td>\n",
       "      <td>You guys are so funny and the bedt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Me too lol</td>\n",
       "      <td>Me too lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Me toooooooooooooooo</td>\n",
       "      <td>Me toooooooooooooooo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Borh is crazy</td>\n",
       "      <td>Borh is crazy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Bro is i scence itüòÆüòÆ</td>\n",
       "      <td>Bro is i scence it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Nah bor</td>\n",
       "      <td>Nah bor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "0   For a second i actually thoughr you borh had c...   \n",
       "1   I was thinking that was Adam and Eve have no c...   \n",
       "2   üòÖüòÇü§£his facial expression and gestic is pricele...   \n",
       "3   you  got ray on  his facial expression isabell...   \n",
       "4             You guys are so funny and the bedt‚ù§‚ù§‚ù§‚ù§‚ù§   \n",
       "..                                                ...   \n",
       "95                                         Me too lol   \n",
       "96                               Me toooooooooooooooo   \n",
       "97                                      Borh is crazy   \n",
       "98                               Bro is i scence itüòÆüòÆ   \n",
       "99                                            Nah bor   \n",
       "\n",
       "                                           clean_text  \n",
       "0   For a second i actually thoughr you borh had c...  \n",
       "1   I was thinking that was Adam and Eve have no c...  \n",
       "2   his facial expression and gestic is pricelessm...  \n",
       "3   you  got ray on  his facial expression isabell...  \n",
       "4                  You guys are so funny and the bedt  \n",
       "..                                                ...  \n",
       "95                                         Me too lol  \n",
       "96                               Me toooooooooooooooo  \n",
       "97                                      Borh is crazy  \n",
       "98                                 Bro is i scence it  \n",
       "99                                            Nah bor  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['text', 'clean_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07c43b2a-8f8f-4f43-8187-46eea5c1d8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def get_sentiment(comment):\n",
    "    analysis = TextBlob(comment)\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return \"Positive\"\n",
    "    elif analysis.sentiment.polarity < 0:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2d4e3fa-a88e-45db-ba65-098eb99e5af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 60 3\n"
     ]
    }
   ],
   "source": [
    "comments = data['clean_text'].tolist()\n",
    "# Apply sentiment analysis\n",
    "sentiment_results = {comment: get_sentiment(comment) for comment in comments}\n",
    "\n",
    "# Print results\n",
    "pos, neu, neg = [0,0,0]\n",
    "for comment, sentiment in sentiment_results.items():\n",
    "    if sentiment == 'Positive': pos += 1\n",
    "    elif sentiment == 'Negative': neg += 1\n",
    "    else: neu +=1\n",
    "print(pos, neu, neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "190b0c6c-6861-45b8-8892-fb169ae47917",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('punkt_tab')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def extract_keywords(text):\n",
    "    words = word_tokenize(text.lower())\n",
    "    words = [word for word in words if word.isalpha() and word not in stop_words]\n",
    "    return Counter(words).most_common(5)  # Top 5 keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a8daf5a-c7c3-4f07-8d1a-f9495453c5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Keywords: [('bro', 8), ('clothes', 6), ('got', 5), ('lol', 5), ('think', 4)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Combine all comments into one text\n",
    "combined_text = \" \".join(comments)\n",
    "\n",
    "keywords = extract_keywords(combined_text)\n",
    "print(\"Top Keywords:\", keywords)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
